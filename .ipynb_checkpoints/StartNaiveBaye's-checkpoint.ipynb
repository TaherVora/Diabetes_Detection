{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1 - Naive Baye's Classifier\n",
    "\n",
    "Upasana Garg - \n",
    "Anurag Singh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "import random \n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' method to read training and test data from file'''\n",
    "def loadTestTrainData():\n",
    "    testData = pd.read_csv('test.csv',delimiter=',')\n",
    "    testData = pd.DataFrame(data=testData, dtype=np.float64)\n",
    "    testData = testData.values.tolist()\n",
    "    '''tData is training data and testData is testing data'''\n",
    "    tData = pd.read_csv('train.csv',delimiter=',')\n",
    "    tData = pd.DataFrame(data=tData, dtype=np.float64)\n",
    "    tData = tData.values.tolist()\n",
    "    return [tData,testData]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' to calculate mean and standard deviation need to categorize data according to the class i.e. 0/1 (last index of the data)''' \n",
    "def categorizeClassData(dataObj): \n",
    "    dataCategory={} \n",
    "    for i in range(len(dataObj)): \n",
    "        dataRow = dataObj[i] \n",
    "        rowLength=len(dataRow)-1 \n",
    "        if(dataRow[rowLength] not in dataCategory): \n",
    "            dataCategory[dataRow[rowLength]]=[] \n",
    "        dataCategory[dataRow[rowLength]].append(dataRow) \n",
    "    '''print(\"data categorized on the basis of the class --- \",dataCategory) '''\n",
    "    return dataCategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' method to calculate standard mean and standard deviation of numbers''' \n",
    "def calculateMeanDeviation(values): \n",
    "    mean=sum(values)/float(len(values))\n",
    "    totalNumerate=0.0 \n",
    "    for i in range(len(values)): \n",
    "        indTerm = pow((values[i]-mean),2) \n",
    "        totalNumerate+=indTerm \n",
    "    variance=totalNumerate/float(len(values)) \n",
    "    deviation=math.sqrt(variance)\n",
    "    return mean,deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' method to all mean and standard deviation on class basis''' \n",
    "def getClassListMeanDev(dataCategory):  \n",
    "    classMeanDevDiff={} \n",
    "    for className,classData in dataCategory.items(): \n",
    "        meanDevList=[] \n",
    "        ''' zip method collects one-one attributes from all data rows for the calculation till end of the row'''\n",
    "        for column in zip(*classData):\n",
    "            dataMean,dataDeviation = calculateMeanDeviation(column) \n",
    "            meanDevList.append((dataMean,dataDeviation)) \n",
    "        ''' to remove last occurance of mean and standard deviation because of existence of class factor''' \n",
    "        meanDevList.pop() \n",
    "        classMeanDevDiff[className] = meanDevList \n",
    "    '''print(\"Data categorization of mean and standard deviation on the basis of className --- \",classMeanDevDiff) '''\n",
    "    return classMeanDevDiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' method to calculate probability according to the gaussian formula - univariate''' \n",
    "def calGaussianFormula(factor,mean,deviation): \n",
    "    expNumerate = math.pow(factor-mean,2) \n",
    "    expDenome= 2*math.pow(deviation,2)  \n",
    "    exponent = math.exp(-(expNumerate/expDenome))  \n",
    "    probab= (1/(math.sqrt(2*math.pi)*deviation))*exponent \n",
    "    '''print(\"Final probability of particular input row according to gaussian formula --- \",probab) '''\n",
    "    return probab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' method to calculate the class probabilities'''  \n",
    "def getClassProbability(classMeanDevDiff,inputRow): \n",
    "    classProbabilities={}\n",
    "    for className,classMeanDev in classMeanDevDiff.items(): \n",
    "        classProbabilities[className] = 1\n",
    "        for j in range(len(classMeanDev)): \n",
    "            mean,deviation=classMeanDev[j] \n",
    "            factor=inputRow[j] \n",
    "            classProbabilities[className]=calGaussianFormula(factor,mean,deviation)\n",
    "    '''print(\"Overall class probabilities are --- \",classProbabilities) '''\n",
    "    return classProbabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' method to check prior class identification on the test data prepared earlier''' \n",
    "def checkPriorClass(classMeanDevDiff,testData): \n",
    "    predictArr=[] \n",
    "    for i in range(len(testData)):\n",
    "        classProbabilities = getClassProbability(classMeanDevDiff,testData[i]) \n",
    "        selectedClass,maxProbab=None,-1 \n",
    "        for className,classProbability in classProbabilities.items(): \n",
    "            if selectedClass is None or classProbability > maxProbab: \n",
    "                maxProbab=classProbability \n",
    "                selectedClass=className\n",
    "        predictArr.append(selectedClass)\n",
    "    '''print(\"Cross check prior identification method on some test data sets --- \",predictArr) '''\n",
    "    return predictArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' method to check the accuracy of the prior prediction of test data set ''' \n",
    "def checkAccuracy(testData,predictArr): \n",
    "    count=0 \n",
    "    for j in range(len(testData)): \n",
    "        tDataClass = testData[j][len(testData[j]) -1]\n",
    "        if tDataClass == predictArr[j]: \n",
    "            count+=1 \n",
    "    accuracyPercent = (count/float(len(testData)))*100 \n",
    "    print(\"Accuracy percent of the test data set --- \",accuracyPercent) \n",
    "    return accuracyPercent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' method to calculate error percentage from accuracy'''\n",
    "def getErrorPercent(accuracyPercent):\n",
    "    return (100.0 - accuracyPercent);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' method to get actual class array from testdata'''\n",
    "def getActualClasses(testData):\n",
    "    actualClass=[]\n",
    "    for j in range(len(testData)):\n",
    "        actualClass.append(testData[j][-1])\n",
    "    return actualClass\n",
    "\n",
    "''' method to get confusion matrix on the basis of actual class data and prediction data'''\n",
    "def getConfusionMatrix(actualArr,predictArr):\n",
    "    actualSeries = pd.Series(actualArr, name='Actual')\n",
    "    predictSeries = pd.Series(predictArr, name='Predicted')\n",
    "    confusionMatrix = pd.crosstab(actualSeries, predictSeries, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "    print(\"Confusion Matrix-------\")\n",
    "    print(confusionMatrix)\n",
    "    return np.matrix(confusionMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''method to get accuracy using confusion matrix   (TP+TN)/(TP+FP+TN+FN)  '''\n",
    "def getAccuracyConfusion(confMatrix):\n",
    "    numer =confMatrix.item(0,0)+confMatrix.item(1,1)\n",
    "    confAccu=numer/confMatrix.item(2,2)\n",
    "    return confAccu\n",
    "\n",
    "'''method to get error using confusion matrix   (FP+FN)/(TP+FP+TN+FN)  '''\n",
    "def getErrorConfusion(confMatrix):\n",
    "    numer =confMatrix.item(0,1)+confMatrix.item(1,0)\n",
    "    confErr=numer/confMatrix.item(2,2)\n",
    "    return confErr\n",
    "\n",
    "'''method to calculate sensitivity    TP / (FN + TP)  '''\n",
    "def getSensitivity(confMatrix):\n",
    "    return confMatrix.item(1,1)/confMatrix.item(1,2)\n",
    "\n",
    "'''method to calculate specificity    TN / (TN/FP)  '''\n",
    "def getSpecificity(confMatrix):\n",
    "    return confMatrix.item(0,0)/confMatrix.item(0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy percent of the test data set ---  64.42687747035573\n",
      "Error percent ---  35.573122529644266\n",
      "Confusion Matrix-------\n",
      "Predicted  0.0  1.0  All\n",
      "Actual                  \n",
      "0.0        107   52  159\n",
      "1.0         38   56   94\n",
      "All        145  108  253\n",
      " Classification Error ---  0.6442687747035574\n",
      " Classifier Error ---  0.3557312252964427\n",
      " Classifier Sensitivity ---  0.5957446808510638\n",
      " Classifier Specificity ---  0.6729559748427673\n"
     ]
    }
   ],
   "source": [
    "''' main method to call other methods'''\n",
    "def runClassifier(): \n",
    "    tData,testData=loadTestTrainData()\n",
    "    '''return dictionary of key-classname and value-dataset'''\n",
    "    dataCategory=categorizeClassData(tData) \n",
    "    \n",
    "    classMeanDevDiff = getClassListMeanDev(dataCategory)\n",
    "    \n",
    "    testPredictArr=checkPriorClass(classMeanDevDiff,testData)\n",
    "    testAccuracy = checkAccuracy(testData,testPredictArr) \n",
    "    \n",
    "    errors = getErrorPercent(testAccuracy)\n",
    "    print(\"Error percent --- \",errors)\n",
    "    \n",
    "    confusionMatrix = getConfusionMatrix(getActualClasses(tData),testPredictArr);\n",
    "    \n",
    "    confAcc=getAccuracyConfusion(confusionMatrix)\n",
    "    print(\" Classification Error --- \",confAcc)\n",
    "    \n",
    "    confErr=getErrorConfusion(confusionMatrix)\n",
    "    print(\" Classifier Error --- \",confErr)\n",
    "    \n",
    "    confSense=getSensitivity(confusionMatrix)\n",
    "    print(\" Classifier Sensitivity --- \",confSense)\n",
    "    \n",
    "    confSpec=getSpecificity(confusionMatrix)\n",
    "    print(\" Classifier Specificity --- \",confSpec)\n",
    "    \n",
    "runClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
